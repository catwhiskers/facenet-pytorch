{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection and recognition training pipeline\n",
    "\n",
    "The following example illustrates how to fine-tune an InceptionResnetV1 model on your own dataset. This will mostly follow standard pytorch training patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd ../ \n",
    "python setup.py install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard==1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define run parameters\n",
    "\n",
    "The dataset should follow the VGGFace2/ImageNet-style directory layout. Modify `data_dir` to the location of the dataset on wish to finetune on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '../data/test_images'\n",
    "data_dir = '/home/ec2-user/SageMaker/lfw'\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "workers = 0 if os.name == 'nt' else 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine if an nvidia GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define MTCNN module\n",
    "\n",
    "See `help(MTCNN)` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perfom MTCNN facial detection\n",
    "\n",
    "Iterate through the DataLoader object and obtain cropped faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/facenet_pytorch-2.5.2-py3.6.egg/facenet_pytorch/models/utils/detect_face.py:183: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  batch_boxes, batch_points = np.array(batch_boxes), np.array(batch_points)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/facenet_pytorch-2.5.2-py3.6.egg/facenet_pytorch/models/mtcnn.py:339: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  boxes = np.array(boxes)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/facenet_pytorch-2.5.2-py3.6.egg/facenet_pytorch/models/mtcnn.py:340: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  probs = np.array(probs)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/facenet_pytorch-2.5.2-py3.6.egg/facenet_pytorch/models/mtcnn.py:341: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  points = np.array(points)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 414 of 414"
     ]
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
    "dataset.samples = [\n",
    "    (p, p.replace(data_dir, data_dir + '_cropped/'))\n",
    "        for p, _ in dataset.samples\n",
    "]\n",
    "        \n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=training.collate_pil\n",
    ")\n",
    "\n",
    "for i, (x, y) in enumerate(loader):\n",
    "    mtcnn(x, save_path=y)\n",
    "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')\n",
    "    \n",
    "# Remove mtcnn to reduce GPU memory usage\n",
    "del mtcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Inception Resnet V1 module\n",
    "\n",
    "See `help(InceptionResnetV1)` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8561aa036d114b139bfb80ede2dcebb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/107M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet = InceptionResnetV1(\n",
    "    classify=True,\n",
    "    pretrained='vggface2',\n",
    "    num_classes=len(dataset.class_to_idx)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define optimizer, scheduler, dataset, and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "scheduler = MultiStepLR(optimizer, [5, 10])\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    np.float32,\n",
    "    transforms.ToTensor(),\n",
    "    fixed_image_standardization\n",
    "])\n",
    "dataset = datasets.ImageFolder(data_dir + '_cropped', transform=trans)\n",
    "img_inds = np.arange(len(dataset))\n",
    "np.random.shuffle(img_inds)\n",
    "train_inds = img_inds[:int(0.8 * len(img_inds))]\n",
    "val_inds = img_inds[int(0.8 * len(img_inds)):]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(train_inds)\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(val_inds)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define loss and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "metrics = {\n",
    "    'fps': training.BatchTimer(),\n",
    "    'acc': training.accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(epochs)\n",
    "epochs = 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Initial\n",
      "----------\n",
      "Valid |    83/83   | loss:    7.1212 | fps:  258.9985 | acc:    0.3510   \n",
      "\n",
      "Epoch 1/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.2391 | fps:   74.8819 | acc:    0.9960   \n",
      "Valid |    83/83   | loss:    7.1156 | fps:  289.5669 | acc:    0.3518   \n",
      "\n",
      "Epoch 2/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.2307 | fps:   81.7622 | acc:    0.9956   \n",
      "Valid |    83/83   | loss:    7.1352 | fps:  289.7765 | acc:    0.3524   \n",
      "\n",
      "Epoch 3/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.2177 | fps:   81.7853 | acc:    0.9967   \n",
      "Valid |    83/83   | loss:    7.1314 | fps:  293.3352 | acc:    0.3513   \n",
      "\n",
      "Epoch 4/50\n",
      "----------\n",
      "Valid |    83/83   | loss:    7.3290 | fps:  291.6987 | acc:    0.3537   \n",
      "\n",
      "Epoch 25/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0892 | fps:   81.3127 | acc:    0.9997   \n",
      "Valid |    83/83   | loss:    7.3442 | fps:  289.9713 | acc:    0.3558   \n",
      "\n",
      "Epoch 26/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0826 | fps:   81.2910 | acc:    0.9994   \n",
      "Valid |    83/83   | loss:    7.3453 | fps:  293.2690 | acc:    0.3550   \n",
      "\n",
      "Epoch 28/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0780 | fps:   81.6812 | acc:    0.9998   \n",
      "Valid |    83/83   | loss:    7.3275 | fps:  291.3188 | acc:    0.3572   \n",
      "\n",
      "Epoch 29/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0760 | fps:   81.6823 | acc:    0.9994   \n",
      "Valid |    83/83   | loss:    7.3628 | fps:  289.4545 | acc:    0.3541   \n",
      "\n",
      "Epoch 30/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0730 | fps:   81.8001 | acc:    0.9998   \n",
      "Valid |    83/83   | loss:    7.3470 | fps:  289.6454 | acc:    0.3584   \n",
      "\n",
      "Epoch 31/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0703 | fps:   81.4397 | acc:    0.9997   \n",
      "Valid |    83/83   | loss:    7.3858 | fps:  293.7517 | acc:    0.3581   \n",
      "\n",
      "Epoch 32/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0655 | fps:   81.3263 | acc:    1.0000   \n",
      "Valid |    83/83   | loss:    7.4269 | fps:  293.7604 | acc:    0.3549   \n",
      "\n",
      "Epoch 33/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0639 | fps:   81.5553 | acc:    1.0000   \n",
      "Valid |    83/83   | loss:    7.3856 | fps:  289.5432 | acc:    0.3561   \n",
      "\n",
      "Epoch 34/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0607 | fps:   81.7552 | acc:    0.9998   \n",
      "Valid |    83/83   | loss:    7.3856 | fps:  289.8816 | acc:    0.3586   \n",
      "\n",
      "Epoch 35/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0581 | fps:   81.3858 | acc:    1.0000   \n",
      "Valid |    83/83   | loss:    7.4099 | fps:  293.2094 | acc:    0.3562   \n",
      "\n",
      "Epoch 36/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0575 | fps:   81.2168 | acc:    0.9999   \n",
      "Valid |    83/83   | loss:    7.3959 | fps:  290.2058 | acc:    0.3594   \n",
      "\n",
      "Epoch 37/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0549 | fps:   81.3089 | acc:    0.9999   \n",
      "Valid |    83/83   | loss:    7.4401 | fps:  289.3102 | acc:    0.3565   \n",
      "\n",
      "Epoch 38/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0525 | fps:   81.4268 | acc:    0.9999   \n",
      "Valid |    83/83   | loss:    7.4627 | fps:  289.4375 | acc:    0.3607   \n",
      "\n",
      "Epoch 39/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0499 | fps:   81.3020 | acc:    1.0000   \n",
      "Valid |    83/83   | loss:    7.4607 | fps:  293.2242 | acc:    0.3590   \n",
      "\n",
      "Epoch 40/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0488 | fps:   81.6223 | acc:    0.9999   \n",
      "Valid |    83/83   | loss:    7.4969 | fps:  290.6996 | acc:    0.3583   \n",
      "\n",
      "Epoch 41/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0462 | fps:   81.5581 | acc:    1.0000   \n",
      "Valid |    83/83   | loss:    7.4709 | fps:  288.7942 | acc:    0.3601   \n",
      "\n",
      "Epoch 42/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0437 | fps:   81.1689 | acc:    1.0000   \n",
      "Valid |    83/83   | loss:    7.5090 | fps:  289.7213 | acc:    0.3574   \n",
      "\n",
      "Epoch 43/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0421 | fps:   81.1958 | acc:    0.9998   \n",
      "Valid |    83/83   | loss:    7.5274 | fps:  293.0995 | acc:    0.3604   \n",
      "\n",
      "Epoch 44/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0409 | fps:   81.6226 | acc:    0.9999   \n",
      "Valid |    83/83   | loss:    7.5004 | fps:  288.7672 | acc:    0.3608   \n",
      "\n",
      "Epoch 45/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0386 | fps:   81.1755 | acc:    0.9999   \n",
      "Valid |    83/83   | loss:    7.5439 | fps:  288.7670 | acc:    0.3601   \n",
      "\n",
      "Epoch 46/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0379 | fps:   81.2047 | acc:    1.0000   \n",
      "Valid |    83/83   | loss:    7.5206 | fps:  288.9897 | acc:    0.3586   \n",
      "\n",
      "Epoch 47/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0362 | fps:   81.2063 | acc:    1.0000   \n",
      "Valid |    83/83   | loss:    7.5265 | fps:  293.2762 | acc:    0.3615   \n",
      "\n",
      "Epoch 48/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0337 | fps:   81.1617 | acc:    1.0000   \n",
      "Valid |    83/83   | loss:    7.5836 | fps:  290.1190 | acc:    0.3583   \n",
      "\n",
      "Epoch 49/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0331 | fps:   81.6567 | acc:    1.0000   \n",
      "Valid |    83/83   | loss:    7.5876 | fps:  289.6662 | acc:    0.3592   \n",
      "\n",
      "Epoch 50/50\n",
      "----------\n",
      "Train |   331/331  | loss:    0.0310 | fps:   81.6950 | acc:    1.0000   \n",
      "Valid |    83/83   | loss:    7.5758 | fps:  289.3315 | acc:    0.3579   \n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "writer.iteration, writer.interval = 0, 10\n",
    "\n",
    "print('\\n\\nInitial')\n",
    "print('-' * 10)\n",
    "resnet.eval()\n",
    "training.pass_epoch(\n",
    "    resnet, loss_fn, val_loader,\n",
    "    batch_metrics=metrics, show_running=True, device=device,\n",
    "    writer=writer\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    resnet.train()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, train_loader, optimizer, scheduler,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "    resnet.eval()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, val_loader,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet, \"fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
